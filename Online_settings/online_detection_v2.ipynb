{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "sNt9Ua2g8dCR",
    "outputId": "2ac0087d-88e1-4716-94d4-31520d7a4b39"
   },
   "outputs": [],
   "source": [
    "!pip  install sk-video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7oZnWo9ALYm_",
    "outputId": "9555b7ce-2a82-4370-c842-f16c7c654e4a"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, Dense, Flatten, ZeroPadding3D, Dropout, Subtract, BatchNormalization\n",
    "import skvideo.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tPIV-Ksfh2Zr"
   },
   "source": [
    "# Base Model\n",
    "\n",
    "Our base model consists of 3D ConvNets from Conv1 to Pool5 and 3 fully connected layers (FC6, FC7, FC8)which has been pre-trained on Sports-1M. We delete the FC8 from our model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjedvEE6LYnF"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'https://github.com/adamcasson/c3d/releases/download/v0.1/sports1M_weights_tf.h5'\n",
    "C3D_MEAN_PATH = 'https://github.com/adamcasson/c3d/releases/download/v0.1/c3d_mean.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0IbdEdZZAJZ"
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "\n",
    "    if K.image_data_format() == 'channels_last':    \n",
    "        shape0 = (16,112,112,3)    \n",
    "    else:   \n",
    "        shape0 = (3,16,112,112)\n",
    "\n",
    "    model_base = Sequential()\n",
    "    \n",
    "    model_base.add(Conv3D(64, 3, activation='relu', padding='same', name='conv1', input_shape=shape0))\n",
    "    model_base.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2), padding='same', name='pool1'))\n",
    "    \n",
    "    model_base.add(Conv3D(128, 3, activation='relu', padding='same', name='conv2'))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool2'))\n",
    "    \n",
    "    model_base.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3a'))\n",
    "    model_base.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3b'))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool3'))\n",
    "    \n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4a'))\n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4b'))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool4'))\n",
    "    \n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5a'))\n",
    "    model_base.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5b'))\n",
    "    model_base.add(ZeroPadding3D(padding=(0,1,1)))\n",
    "    model_base.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool5'))\n",
    "    \n",
    "    model_base.add(Flatten())\n",
    "    \n",
    "    model_base.add(Dense(4096, activation='relu', name='fc6'))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(4096, activation='relu', name='fc7'))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(487, activation='softmax', name='fc8'))\n",
    "\n",
    "    weights_path = get_file('sports1M_weights_tf.h5',\n",
    "                         WEIGHTS_PATH,\n",
    "                         cache_subdir='models',\n",
    "                         md5_hash='b7a93b2f9156ccbebe3ca24b41fc5402')\n",
    "        \n",
    "    model_base.load_weights(weights_path)\n",
    "\n",
    "    model_base.pop()\n",
    "    \n",
    "    return model_base\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6r0t6tKxjtD_"
   },
   "source": [
    "# Model the Temporal Consistency\n",
    "\n",
    "We add a clasification layer FC8 to our model, that gives the class of the actual window (background or action). We also add a second loss to our model, that mesures the difference between the FC7 layer for the actual window and the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "ErFTGOPbbTN7",
    "outputId": "0b8fe1bb-dc9b-4584-e65b-92219302b326"
   },
   "outputs": [],
   "source": [
    "model_base = base_model()\n",
    "\n",
    "if K.image_data_format() == 'channels_last':    \n",
    "    shape0 = (16,112,112,3)    \n",
    "else:   \n",
    "    shape0 = (3,16,112,112)\n",
    "\n",
    "start_window = Input(shape=shape0, dtype='float32', name='start_window')\n",
    "followup_window = Input(shape=shape0, dtype='float32', name='followup_window')\n",
    "\n",
    "fc7 =model_base(start_window)\n",
    "\n",
    "drop2 = Dropout(0.5)(fc7)\n",
    "fc8 = Dense(2, activation='sigmoid', name='fc8')(drop2)\n",
    "\n",
    "\n",
    "out1 = fc7\n",
    "out2 = model_base(followup_window)\n",
    "\n",
    "out = Subtract(name='out')([out1, out2])\n",
    "\n",
    "model_1 = Model([start_window,followup_window],[fc8,out])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wcw9IpFpg2VK"
   },
   "outputs": [],
   "source": [
    "def loss_classification(y_true, y_pred):\n",
    "    return -K.mean(K.log(K.dot(y_pred,K.transpose(y_true))), axis=-1)\n",
    "    \n",
    "def loss_temporal_consistency(y_true,y_pred):\n",
    "    return K.mean(K.square(K.dot(y_pred,K.transpose(y_true))), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGm0m4eLg_mS"
   },
   "outputs": [],
   "source": [
    "model_1.compile(optimizer='adam',\n",
    "              loss={'fc8': loss_classification, 'out': loss_temporal_consistency},\n",
    "              loss_weights={'fc8': 1., 'out': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLMSr679krzu"
   },
   "source": [
    "# Training phase 1 \n",
    "We train our model_1 by minimizing $\\mathcal{L}_{classification} + \\lambda\\mathcal{L}_{similarity}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "3_sja5gW9Ir0",
    "outputId": "56303dff-e09d-456a-9f77-6d6bfe6ace32"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "path1 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Normal/Training_Normal_Videos_Anomaly/Normal_Videos001_x264.mp4'\n",
    "path2 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Abnormal/Abuse/Abuse001_x264.mp4'\n",
    "\n",
    "\n",
    "Normal_Video = skvideo.io.vread(path1,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "Abnormal_Video = skvideo.io.vread(path2,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "action_intervals = [[230, 365], [-1,-1]]\n",
    "\n",
    "Videos = [Normal_Video, Abnormal_Video]\n",
    "\n",
    "\n",
    "# Let's train the model on two videos (Extansion well be easy)\n",
    "# We do just on training iteration, in which we create one batch containing Nb_training_examples = Nb_abnormal*15\n",
    "\n",
    "print(\"Constructing Postive Exapmles\")\n",
    "positive_indexes = []\n",
    "\n",
    "count = -1\n",
    "for action in range(len(action_intervals)):\n",
    "    positive_indexes.append([])\n",
    "    start = action_intervals[action][0]\n",
    "    idx = 0\n",
    "    while (start!=-1) and (idx < len(action_intervals[action])):\n",
    "        start = action_intervals[action][idx]\n",
    "        idx += 2\n",
    "        positive_indexes[action] = positive_indexes[action]+([start-15+i for i in range(15)])\n",
    "    \n",
    "        for i in range(15):\n",
    "            count += 1\n",
    "            if(count==0):\n",
    "                actuals = np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)\n",
    "                nexts = np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)\n",
    "            if(count>0):\n",
    "                actuals = np.vstack((actuals, np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)))\n",
    "                nexts   = np.vstack((nexts, np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)))\n",
    "\n",
    "nbr_positive = actuals.shape[0]\n",
    "print(\"Constructing Negativve Exapmles\")\n",
    "\n",
    "nbr_neg = 0 # nbr of negative examples selected \n",
    "while (nbr_neg<nbr_positive):\n",
    "    video_indx = random.randint(0,len(Videos)-1) #Pick randomly a video \n",
    "    start_frame = random.randint(0,Videos[video_indx].shape[0]-33)\n",
    "  \n",
    "    while (start_frame in positive_indexes[video_indx]):\n",
    "        start_frame = random.randint(0,Videos[video_indx].shape[0]-33) #pick a new sequence till it is abnormal\n",
    "    nbr_neg = nbr_neg + 1\n",
    "  \n",
    "    actuals = np.vstack((actuals, np.expand_dims(Videos[video_indx][start_frame:start_frame+16], axis=0)))\n",
    "    nexts   = np.vstack((nexts, np.expand_dims(Videos[video_indx][start_frame+16:start_frame+32], axis=0)))\n",
    "\n",
    "\n",
    "inputs = [actuals, nexts]\n",
    "labels = np.zeros((nbr_positive+nbr_neg,1))\n",
    "labels[0:nbr_positive,:] += 1 \n",
    "\n",
    "labels_1 = labels\n",
    "\n",
    "labels = np.zeros((nbr_positive+nbr_neg,4096))\n",
    "labels[0:nbr_positive,:] += 1\n",
    "\n",
    "labels_2 = labels\n",
    "\n",
    "labels = [labels_1, labels_2]\n",
    "\n",
    "\n",
    "print(\"Start Training\")\n",
    "loss = model_1.train_on_batch(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUbmWmpBPx5I"
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Z9S5XCYmYP1"
   },
   "source": [
    "# Generate Hard Negative Samples via GAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator \n",
    "\n",
    "The generator takes as input a 100-dimensional noise, It is composed of two fully-connected layers of 8192 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(8192, activation='relu', name='fc1',input_shape=(100,)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Dense(8192, activation='relu', name='fc2'))\n",
    "generator.add(BatchNormalization())\n",
    "\n",
    "generator.name='generator'\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Block and FC6+FC7 block\n",
    "\n",
    "We create a block model containing all the covolutional layers of the base_model till pool5, And we get a modedl composed of layers fc6 and fc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Sequential()\n",
    "conv_model.name = 'conv_model'\n",
    "\n",
    "fc6_fc7_model = Sequential()\n",
    "fc6_fc7_model.name = 'fc6_fc7_model'\n",
    "\n",
    "index = 0 # 0 to add layers in conv_model, and \n",
    "for layer in model_1.get_layer(index=1).layers:\n",
    "    if(index == 0):\n",
    "        conv_model.add(layer)\n",
    "    if(index == 1):\n",
    "        fc6_fc7_model.add(layer)\n",
    "        \n",
    "    if(layer.name == 'flatten_1'):\n",
    "        index = 1\n",
    "        \n",
    "print(conv_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriminator \n",
    "\n",
    "We use the blocks that we have created to create the Descriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_window = Input(shape=(8192,), dtype='float32', name='actual_window')\n",
    "next_window = Input(shape=(8192,), dtype='float32', name='next_window')\n",
    "noise = Input(shape=(100,), dtype='float32', name='noise')\n",
    "\n",
    "generated_sample = fc6_fc7_model(generator(noise))\n",
    "\n",
    "actual_window_fc7 = fc6_fc7_model(actual_window)\n",
    "next_window_fc7 = fc6_fc7_model(next_window)\n",
    "\n",
    "\n",
    "classification_out = Dense(3, activation='softmax', name='classification_out')(actual_window_fc7) \n",
    "\n",
    "similarity_out =  Subtract(name='similarity_out')([actual_window_fc7, next_window_fc7])\n",
    "\n",
    "matching_out = Subtract(name='matching_out')([generated_sample, actual_window_fc7])\n",
    "\n",
    "global_model = Model([actual_window, next_window, noise],[classification_out, similarity_out, matching_out])\n",
    "\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase 2\n",
    "\n",
    "In this part we train the model globally. The convolutional part of the model is not trained at all, it is not even tooken into acount in the model, and we only use the pool5 features obtained from each video sequence as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all this part we set the weights of the Convolutional layers to be not trainable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train First the generator, It is to do we should just set all the wieghts expet FC1 and FC2 to be not trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_trainable(fc6_fc7_model, False)\n",
    "make_trainable(generator, True)\n",
    "global_model.compile(optimizer='adam',\n",
    "              loss={'classification_out': loss_classification, 'similarity_out': loss_temporal_consistency, 'matching_out' : loss_temporal_consistency},\n",
    "              loss_weights={'classification_out': 0., 'similarity_out': 0., 'matching_out': 1.})\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "path1 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Normal/Training_Normal_Videos_Anomaly/Normal_Videos001_x264.mp4'\n",
    "path2 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Abnormal/Abuse/Abuse001_x264.mp4'\n",
    "\n",
    "\n",
    "Normal_Video = skvideo.io.vread(path1,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "Abnormal_Video = skvideo.io.vread(path2,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "action_intervals = [[230, 365], [-1,-1]]\n",
    "\n",
    "Videos = [Normal_Video, Abnormal_Video]\n",
    "\n",
    "\n",
    "\n",
    "# Let's train the model on two videos (Extansion well be easy)\n",
    "# We do just on training iteration, in which we create one batch containing Nb_training_examples = Nb_abnormal*15\n",
    "print(\"Constructing Postive Exapmles\")\n",
    "positive_indexes = []\n",
    "\n",
    "count = -1\n",
    "for action in range(len(action_intervals)):\n",
    "    positive_indexes.append([])\n",
    "    start = action_intervals[action][0]\n",
    "    idx = 0\n",
    "    while (start!=-1) and (idx < len(action_intervals[action])):\n",
    "        start = action_intervals[action][idx]\n",
    "        idx += 2\n",
    "        positive_indexes[action] = positive_indexes[action]+([start-15+i for i in range(15)])\n",
    "    \n",
    "        for i in range(15):\n",
    "            count += 1\n",
    "            if(count==0):\n",
    "                actuals = np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)\n",
    "                nexts = np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)\n",
    "            if(count>0):\n",
    "                actuals = np.vstack((actuals, np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)))\n",
    "                nexts   = np.vstack((nexts, np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)))\n",
    "\n",
    "nbr_positive = actuals.shape[0]\n",
    "print(\"Constructing Negativve Exapmles\")\n",
    "\n",
    "nbr_neg = 0 # nbr of negative examples selected \n",
    "while (nbr_neg<nbr_positive):\n",
    "    video_indx = random.randint(0,len(Videos)-1) #Pick randomly a video \n",
    "    start_frame = random.randint(0,Videos[video_indx].shape[0]-33)\n",
    "  \n",
    "    while (start_frame in positive_indexes[video_indx]):\n",
    "        start_frame = random.randint(0,Videos[video_indx].shape[0]-33) #pick a new sequence till it is abnormal\n",
    "    nbr_neg = nbr_neg + 1\n",
    "  \n",
    "    actuals = np.vstack((actuals, np.expand_dims(Videos[video_indx][start_frame:start_frame+16], axis=0)))\n",
    "    nexts   = np.vstack((nexts, np.expand_dims(Videos[video_indx][start_frame+16:start_frame+32], axis=0)))\n",
    "\n",
    "\n",
    "noises = np.random.normal(size=(nbr_positive+nbr_neg,100))\n",
    "\n",
    "inputs = [conv_model.predict(actuals), conv_model.predict(nexts), noises]\n",
    "\n",
    "\n",
    "labels_classification = np.zeros((nbr_positive+nbr_neg,3))\n",
    "\n",
    "labels_similarity = np.zeros((nbr_positive+nbr_neg,4096))\n",
    "\n",
    "labels_matching = np.ones((nbr_positive+nbr_neg,4096))\n",
    "\n",
    "labels = [labels_classification, labels_similarity, labels_matching]\n",
    "\n",
    "print(\"Start Training Generator\")\n",
    "loss = global_model.train_on_batch(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train now the discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_trainable(fc6_fc7_model, True)\n",
    "make_trainable(generator, False)\n",
    "global_model.compile(optimizer='adam',\n",
    "              loss={'classification_out': loss_classification, 'similarity_out': loss_temporal_consistency, 'matching_out' : loss_temporal_consistency},\n",
    "              loss_weights={'classification_out': 1., 'similarity_out': 1., 'matching_out': 0.})\n",
    "\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "path1 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Normal/Training_Normal_Videos_Anomaly/Normal_Videos001_x264.mp4'\n",
    "path2 = 'D:/workspace/MVA/ORCV/Final_Project/Data_Sets/UCF-Anomaly-Detection-Dataset/UCF_Crimes/Videos/Abnormal/Abuse/Abuse001_x264.mp4'\n",
    "\n",
    "\n",
    "Normal_Video = skvideo.io.vread(path1,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "Abnormal_Video = skvideo.io.vread(path2,\n",
    "                          outputdict={\n",
    "                            \"-sws_flags\": \"bilinear\",\n",
    "                            \"-s\": \"112x112\"\n",
    "                          })\n",
    "\n",
    "action_intervals = [[230, 365], [-1,-1]]\n",
    "\n",
    "Videos = [Normal_Video, Abnormal_Video]\n",
    "\n",
    "\n",
    "\n",
    "# Let's train the model on two videos (Extansion well be easy)\n",
    "# We do just on training iteration, in which we create one batch containing Nb_training_examples = Nb_abnormal*15\n",
    "print(\"Constructing Postive Exapmles\")\n",
    "positive_indexes = []\n",
    "\n",
    "count = -1\n",
    "for action in range(len(action_intervals)):\n",
    "    positive_indexes.append([])\n",
    "    start = action_intervals[action][0]\n",
    "    idx = 0\n",
    "    while (start!=-1) and (idx < len(action_intervals[action])):\n",
    "        start = action_intervals[action][idx]\n",
    "        idx += 2\n",
    "        positive_indexes[action] = positive_indexes[action]+([start-15+i for i in range(15)])\n",
    "    \n",
    "        for i in range(15):\n",
    "            count += 1\n",
    "            if(count==0):\n",
    "                actuals = np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)\n",
    "                nexts = np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)\n",
    "            if(count>0):\n",
    "                actuals = np.vstack((actuals, np.expand_dims(Videos[action][start-15+i:start+i+1], axis=0)))\n",
    "                nexts   = np.vstack((nexts, np.expand_dims(Videos[action][start+i+1:start+i+17], axis=0)))\n",
    "\n",
    "nbr_positive = actuals.shape[0]\n",
    "print(\"Constructing Negativve Exapmles\")\n",
    "\n",
    "nbr_neg = 0 # nbr of negative examples selected \n",
    "while (nbr_neg<nbr_positive):\n",
    "    video_indx = random.randint(0,len(Videos)-1) #Pick randomly a video \n",
    "    start_frame = random.randint(0,Videos[video_indx].shape[0]-33)\n",
    "  \n",
    "    while (start_frame in positive_indexes[video_indx]):\n",
    "        start_frame = random.randint(0,Videos[video_indx].shape[0]-33) #pick a new sequence till it is abnormal\n",
    "    nbr_neg = nbr_neg + 1\n",
    "  \n",
    "    actuals = np.vstack((actuals, np.expand_dims(Videos[video_indx][start_frame:start_frame+16], axis=0)))\n",
    "    nexts   = np.vstack((nexts, np.expand_dims(Videos[video_indx][start_frame+16:start_frame+32], axis=0)))\n",
    "\n",
    "\n",
    "\n",
    "actuals = conv_model.predict(actuals)\n",
    "nexts = conv_model.predict(nexts)\n",
    "\n",
    "\n",
    "noises = np.random.normal(size=(nbr_positive,100))\n",
    "actuals = np.vstack((actuals, generator.predict(noises)))\n",
    "nexts = np.vstack((nexts, generator.predict(noises)))\n",
    "\n",
    "noises = np.random.normal(size=(3*nbr_positive,100))\n",
    "inputs = [actuals, nexts, noises]\n",
    "\n",
    "\n",
    "labels_classification = np.zeros((3*nbr_positive,3))\n",
    "\n",
    "labels_classification[:nbr_positive,0] = 1\n",
    "labels_classification[nbr_positive:(2*nbr_positive),1] = 1\n",
    "labels_classification[(2*nbr_positive):,2] = 1\n",
    "\n",
    "\n",
    "labels_similarity = np.zeros((3*nbr_positive,4096))\n",
    "labels_classification[:nbr_positive] = 1\n",
    "\n",
    "\n",
    "labels_matching = np.zeros((3*nbr_positive,4096))\n",
    "\n",
    "labels = [labels_classification, labels_similarity, labels_matching]\n",
    "\n",
    "print(\"Start Training Generator\")\n",
    "loss = global_model.train_on_batch(inputs, labels)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "c3d.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
